{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3fb16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gan import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0655167e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# g_lr = 0.000\n",
    "# d_lr = 0.00002\n",
    "# recolorizer_lr = 0.0001\n",
    "\n",
    "# for receptive_field in [4]:\n",
    "#     model_type = (\n",
    "#         f\"euclidean-g={g_lr}-d={d_lr}-r={recolorizer_lr}-rf={receptive_field}\"\n",
    "#     )\n",
    "\n",
    "#     train_gan(\n",
    "#         \".\",\n",
    "#         model_type,\n",
    "#         \"cifar\",\n",
    "#         \"rgb\",\n",
    "#         \"cuda\",\n",
    "#         batch_size=16,\n",
    "#         epochs=200,\n",
    "#         receptive_field=receptive_field,\n",
    "#         g_lr=g_lr,\n",
    "#         d_lr=d_lr,\n",
    "#         recolorizer_lr=recolorizer_lr,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb867820",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0/100][0/3125] Loss_D: 1.8676 Loss_G: 3.7582 D(x): 0.4995 D(G(z)): 0.6237 / 0.6237\n",
      "saving the output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][0/3125] Loss_D: 1.8676 Loss_G: 3.7582 D(x): 0.4995 D(G(z)): 0.6237 / 0.6237\n",
      "saving the output\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 296\u001b[0m\n\u001b[1;32m    293\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(netG\u001b[38;5;241m.\u001b[39mstate_dict(), g_model_save_path)\n\u001b[1;32m    294\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(netD\u001b[38;5;241m.\u001b[39mstate_dict(), d_model_save_path)\n\u001b[0;32m--> 296\u001b[0m \u001b[43mtrain_normal_ci_gan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtesting_learning_rates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcifar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolorspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0003\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\n\u001b[1;32m    306\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [1], line 207\u001b[0m, in \u001b[0;36mtrain_normal_ci_gan\u001b[0;34m(base_path, model_type, dataset_name, colorspace, device, D_criterion, G_criterion, epochs, batch_size, g_lr, d_lr)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m############################\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m###########################\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# train with real\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     netD\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 207\u001b[0m     real_cpu \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m real_cpu\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    209\u001b[0m     d_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((batch_size,), real_label, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import transforms\n",
    "\n",
    "from data import load_data_gan\n",
    "from layers import EuclideanColorInvariantConv2d, LearnedColorInvariantConv2d, SquaredEuclideanColorInvariantConv2d, AbsColorInvariantConv2d\n",
    "from test_cases import test\n",
    "cudnn.benchmark = True\n",
    "\n",
    "def train_normal_ci_gan(base_path: Path,\n",
    "    model_type,\n",
    "    dataset_name,\n",
    "    colorspace,\n",
    "    device,\n",
    "    D_criterion = nn.BCELoss(),\n",
    "    G_criterion = nn.BCELoss(),\n",
    "    epochs=25,\n",
    "    batch_size=128,\n",
    "    g_lr=0.0003,\n",
    "    d_lr=0.0001):\n",
    "\n",
    "    # custom weights initialization called on netG and netD\n",
    "    def weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, ngpu, nz, ngf, nc, mult=2):\n",
    "            super(Generator, self).__init__()\n",
    "            self.ngpu = ngpu\n",
    "            self.nz = nz\n",
    "            self.ngf = ngf\n",
    "            self.nc = nc\n",
    "            self.mult = mult\n",
    "            self.main = nn.Sequential(\n",
    "                # input is Z, going into a convolution\n",
    "                nn.ConvTranspose2d(self.nz, self.ngf * 8 * mult, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(self.ngf * 8 * mult),\n",
    "                nn.ReLU(True),\n",
    "                # state size. (self.ngf*8) x 4 x 4\n",
    "                nn.ConvTranspose2d(self.ngf * 8 * mult, self.ngf * 4 * 8 * mult, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(self.ngf * 4 * 8 * mult),\n",
    "                nn.ReLU(True),\n",
    "                # state size. (self.ngf*4) x 8 x 8\n",
    "                nn.ConvTranspose2d(self.ngf * 4 * 8 * mult, self.ngf * 2 * 8, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(self.ngf * 2 * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. (self.ngf*2) x 16 x 16\n",
    "                nn.ConvTranspose2d(self.ngf * 2 * 8, self.ngf * 8, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(self.ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. (self.ngf) x 32 x 32\n",
    "                nn.ConvTranspose2d(self.ngf * 8, self.nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. (self.nc) x 64 x 64\n",
    "                # # input is Z, going into a convolution\n",
    "                # nn.ConvTranspose2d(self.nz, self.ngf * 8 * mult, 4, 1, 0, bias=False),\n",
    "                # nn.BatchNorm2d(self.ngf * 8 * mult),\n",
    "                # nn.ReLU(True),\n",
    "                # # state size. (self.ngf*8) x 4 x 4\n",
    "                # nn.ConvTranspose2d(self.ngf * 8 * mult, self.ngf * 4 * 8 * mult, 4, 2, 1, bias=False),\n",
    "                # nn.BatchNorm2d(self.ngf * 4 * 8 * mult),\n",
    "                # nn.ReLU(True),\n",
    "                # # state size. (self.ngf*4) x 8 x 8\n",
    "                # nn.ConvTranspose2d(self.ngf * 4 * 8 * mult, self.ngf * 2 * 8 * mult, 4, 2, 1, bias=False),\n",
    "                # nn.BatchNorm2d(self.ngf * 2 * 8 * mult),\n",
    "                # nn.ReLU(True),\n",
    "                # # state size. (self.ngf*2) x 16 x 16\n",
    "                # nn.ConvTranspose2d(self.ngf * 2 * 8 * mult, self.ngf * 8 * self.mult, 4, 2, 1, bias=False),\n",
    "                # nn.BatchNorm2d(self.ngf * 8 * self.mult),\n",
    "                # nn.ReLU(True),\n",
    "                # # state size. (self.ngf) x 32 x 32\n",
    "                # nn.ConvTranspose2d(self.ngf * 8 * self.mult, self.nc, 4, 2, 1, bias=False),\n",
    "                # nn.Tanh()\n",
    "                # # state size. (self.nc) x 64 x 64\n",
    "            )\n",
    "\n",
    "        def forward(self, input):\n",
    "            if input.is_cuda and self.ngpu > 1:\n",
    "                output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "            else:\n",
    "                output = self.main(input)\n",
    "            noise = torch.randn(output.shape, device=device) / 100000\n",
    "            # print(noise.min(), noise.max())\n",
    "            output = output + noise\n",
    "            return output\n",
    "\n",
    "    class Discriminator(nn.Module):\n",
    "        def __init__(self, ngpu, ndf, nc, mult=1):\n",
    "            super(Discriminator, self).__init__()\n",
    "            self.ngpu = ngpu\n",
    "            self.main = nn.Sequential(\n",
    "                # input is (nc) x 64 x 64\n",
    "                AbsColorInvariantConv2d(nc, ndf * mult, 4, 2, 1, bias=False),\n",
    "                # SquaredEuclideanColorInvariantConv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. (ndf) x 32 x 32\n",
    "                nn.Conv2d(ndf * mult, ndf * 2 * mult, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ndf * 2 * mult),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. (ndf*2) x 16 x 16\n",
    "                nn.Conv2d(ndf * 2 * mult, ndf * 4 * mult, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ndf * 4 * mult),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. (ndf*4) x 8 x 8\n",
    "                nn.Conv2d(ndf * 4 * mult, ndf * 8 * mult, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ndf * 8 * mult),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                # state size. (ndf*8) x 4 x 4\n",
    "                nn.Conv2d(ndf * 8 * mult, 1, 4, 1, 0, bias=False),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        def forward(self, input):\n",
    "            if input.is_cuda and self.ngpu > 1:\n",
    "                output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "            else:\n",
    "                output = self.main(input)\n",
    "\n",
    "            return output.view(-1, 1).squeeze(1)\n",
    "\n",
    "    if not isinstance(base_path, Path):\n",
    "        base_path = Path(base_path)\n",
    "\n",
    "    output_file = (\n",
    "        base_path\n",
    "        / \"logs\"\n",
    "        / (\"gan_\" + model_type + \"_\" + dataset_name + \"_\" + colorspace + \".txt\")\n",
    "    )\n",
    "    logger = logging.root\n",
    "    file_handler = logging.FileHandler(output_file, mode=\"w\")\n",
    "    stream_handler = logging.StreamHandler()\n",
    "\n",
    "    logger.setLevel(logging.INFO)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    # load dataset\n",
    "    dataloader, nc = load_data_gan(\n",
    "        dataset=dataset_name,\n",
    "        colorspace=colorspace,\n",
    "        batch_size=batch_size,\n",
    "        train_prop=1,\n",
    "    )\n",
    "\n",
    "    sample = next(iter(dataloader))\n",
    "    sample_dims = sample[0].shape\n",
    "    total_pixels_per_batch = sample_dims[0] * sample_dims[2] * sample_dims[3]\n",
    "\n",
    "    #checking the availability of cuda devices\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    nc=3\n",
    "    # number of gpu's available\n",
    "    ngpu = 1\n",
    "    # input noise dimension\n",
    "    nz = 256\n",
    "    # number of generator filters\n",
    "    ngf = 64\n",
    "    #number of discriminator filters\n",
    "    ndf = 64\n",
    "\n",
    "    netG = Generator(ngpu=ngpu, nz=nz, ngf=ngf, nc=nc).to(device)\n",
    "    netG.apply(weights_init)\n",
    "\n",
    "    netD = Discriminator(ngpu, ndf, nc).to(device)\n",
    "    netD.apply(weights_init)\n",
    "\n",
    "    # setup optimizer\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=d_lr, betas=(0.5, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=g_lr, betas=(0.5, 0.999))\n",
    "\n",
    "    fixed_noise = torch.randn(128, nz, 1, 1, device=device)\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "\n",
    "    g_loss = []\n",
    "    d_loss = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            ############################\n",
    "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            ###########################\n",
    "            # train with real\n",
    "            netD.zero_grad()\n",
    "            real_cpu = data[0].to(device)\n",
    "            batch_size = real_cpu.size(0)\n",
    "            d_label = torch.full((batch_size,), real_label, device=device).float()\n",
    "\n",
    "            output = netD(real_cpu)\n",
    "            errD_real = D_criterion(output, d_label)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            # train with fake\n",
    "            noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "\n",
    "            # Note: Output must be clipped to valid range because discriminator does not know valid range anymore (would accept negative pixel values if given)\n",
    "            # fake = torch.clip(netG(noise), 0, 1)\n",
    "\n",
    "            fake = netG(noise)\n",
    "            d_label.fill_(fake_label)\n",
    "            output = netD(fake.detach())\n",
    "            errD_fake = D_criterion(output, d_label)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            errD = errD_real + errD_fake\n",
    "            optimizerD.step()\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network: maximize log(D(G(z)))\n",
    "            ###########################\n",
    "            netG.zero_grad()\n",
    "            d_label.fill_(real_label)  # fake labels are real for generator cost\n",
    "            consistency_output = netD(fake)\n",
    "\n",
    "            consistency_loss = G_criterion(consistency_output, d_label)\n",
    "            errG = consistency_loss\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optimizerG.step()\n",
    "\n",
    "            #save the output\n",
    "            if i % 100 == 0:\n",
    "                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' % (epoch, epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "                logging.info('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' % (epoch, epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "                normal_image_path = (\n",
    "                    base_path\n",
    "                    / \"images\"\n",
    "                    / (f\"{dataset_name}.png\")\n",
    "                )\n",
    "                print('saving the output')\n",
    "                logging.info('saving the output')\n",
    "                vutils.save_image(real_cpu,normal_image_path,normalize=False)\n",
    "                # fake = torch.clip(netG(fixed_noise), 0, 1)\n",
    "                fake = netG(fixed_noise)\n",
    "                fake = torch.clip((fake - fake.min()), 0, 1)\n",
    "                generated_image_path = (\n",
    "                    base_path\n",
    "                    / \"images\"\n",
    "                    / (f\"gan_{model_type}_{dataset_name}_{colorspace}_{epoch}.png\")\n",
    "                )\n",
    "                vutils.save_image(fake.detach(),generated_image_path,normalize=False)\n",
    "\n",
    "        # save latest\n",
    "        if epoch % 5 == 0:\n",
    "            g_model_save_path = (\n",
    "                base_path\n",
    "                / \"models\"\n",
    "                / (\"gan_\" + model_type + \"_\" + dataset_name + \"_\" + colorspace + f\"_g_{epoch}.pth\")\n",
    "            )\n",
    "            d_model_save_path = (\n",
    "                base_path\n",
    "                / \"models\"\n",
    "                / (\"gan_\" + model_type + \"_\" + dataset_name + \"_\" + colorspace + f\"_d_{epoch}.pth\")\n",
    "            )\n",
    "            # Check pointing for every epoch\n",
    "            torch.save(netG.state_dict(), g_model_save_path)\n",
    "            torch.save(netD.state_dict(), d_model_save_path)\n",
    "\n",
    "        g_model_save_path = (\n",
    "            base_path\n",
    "            / \"models\"\n",
    "            / (\"gan_\" + model_type + \"_\" + dataset_name + \"_\" + colorspace + f\"_g_latest.pth\")\n",
    "        )\n",
    "        d_model_save_path = (\n",
    "            base_path\n",
    "            / \"models\"\n",
    "            / (\"gan_\" + model_type + \"_\" + dataset_name + \"_\" + colorspace + f\"_d_latest.pth\")\n",
    "        )\n",
    "        # Check pointing for every epoch\n",
    "        torch.save(netG.state_dict(), g_model_save_path)\n",
    "        torch.save(netD.state_dict(), d_model_save_path)\n",
    "\n",
    "train_normal_ci_gan(\n",
    "    base_path='.',\n",
    "    model_type=\"testing_learning_rates\",\n",
    "    dataset_name=\"cifar\",\n",
    "    colorspace=\"rgb\",\n",
    "    device=\"cuda\",\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    g_lr=0.0003,\n",
    "    d_lr=0.0001\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
